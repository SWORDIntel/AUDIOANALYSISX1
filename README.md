# Voice Manipulation Detection Pipeline

<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘   â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â•‘
â•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—    â•‘
â•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â•‘
â•‘   â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•      â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â•‘
â•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â•‘
â•‘     â•šâ•â•â•â•   â•šâ•â•â•â•â•â• â•šâ•â• â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•     â•‘
â•‘                                                                              â•‘
â•‘              FORENSIC AUDIO MANIPULATION DETECTION SYSTEM                   â•‘
â•‘                  Tactical Implementation Specification                       â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**A multi-phase forensic analysis pipeline for detecting voice manipulation through pitch-shifting and time-stretching artifacts.**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

[Features](#features) â€¢ [Installation](#installation) â€¢ [Quick Start](#quick-start) â€¢ [Documentation](#documentation) â€¢ [Examples](#examples)

</div>

---

## ğŸ¯ Overview

This pipeline implements a **5-phase forensic audio analysis system** designed to detect voice manipulation and AI-generated voices, including:

- **Pitch-shifting** (male â†” female voice conversion)
- **Time-stretching** (speed manipulation)
- **Phase vocoder artifacts** (deepfake/alteration signatures)
- **Combined manipulations** (multi-vector attacks)
- **AI-generated voices** (TTS, voice cloning, deepfakes)
- **Neural vocoder detection** (WaveNet, WaveGlow, HiFi-GAN)

The system uses **multiple independent detection methods** across manipulation detection and AI voice detection to provide high-confidence results with cryptographically verifiable outputs.

### ğŸ”¬ How It Works

Voice manipulators typically alter **pitch (F0)** to change perceived gender, but they cannot easily change **formants** (physical vocal tract resonances). This creates a detectable **pitch-formant incoherence** that serves as forensic evidence.

```
CLEAN AUDIO:     F0 = 120 Hz (Male) âœ“ + Formants = Male âœ“ â†’ COHERENT
MANIPULATED:     F0 = 220 Hz (Female) âœ— + Formants = Male âœ“ â†’ INCOHERENT âš 
```

---

## âœ¨ Features

### ğŸ” Multi-Phase Detection

- **PHASE 1:** Baseline F0 Analysis - Isolates presented pitch
- **PHASE 2:** Vocal Tract Analysis - Extracts physical formant characteristics
- **PHASE 3:** Manipulation Artifact Detection - Three independent methods:
  - ğŸµ Pitch-Formant Incoherence Detection
  - ğŸ“Š Mel Spectrogram Artifact Analysis
  - âš¡ Phase Decoherence / Transient Smearing Detection
- **PHASE 4:** AI Voice Detection - Six independent methods:
  - ğŸ¤– Neural Vocoder Artifact Detection
  - ğŸ­ Prosody & Naturalness Analysis
  - ğŸ« Breathing & Pause Pattern Analysis
  - â±ï¸ Micro-timing Consistency Analysis
  - ğŸ¼ Harmonic Structure Analysis
  - ğŸ“Š Statistical Feature Anomaly Detection
- **PHASE 5:** Report Synthesis - Generates verified, tamper-evident reports

### ğŸŒ Web GUI (NEW)

Modern web-based interface with:
- ğŸ–±ï¸ Drag-and-drop file upload
- ğŸ“Š Real-time visualization updates
- ğŸ“¥ One-click report downloads (JSON, Markdown, CSV)
- ğŸ“ Batch processing with progress bars
- ğŸ¨ Dark theme with responsive layout
- ğŸŒ Shareable links for demos

### ğŸ–¥ï¸ Interactive TUI

Beautiful terminal interface with:
- Real-time progress tracking
- Color-coded results
- Interactive menus
- Batch processing support

### ğŸ”’ Verifiable Outputs

Every analysis includes:
- **SHA-256 checksums** of audio files
- **Cryptographic signatures** for tamper detection
- **Chain of custody** metadata
- **Multiple output formats** (JSON, Markdown, visualizations)

### ğŸ“Š Comprehensive Visualizations

Generates 4 plots per analysis:
- Overview dashboard
- Mel spectrogram with artifact annotations
- Phase coherence analysis
- Pitch-formant comparison chart

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10 or higher
- pip package manager
- 4GB RAM minimum

### Quick Install

```bash
# Clone or navigate to the project directory
cd /home/john/voice

# Install dependencies
pip install -r requirements.txt
```

### Dependencies

```
librosa>=0.10.0          # Audio analysis
numpy>=1.24.0            # Numerical computing
scipy>=1.10.0            # Signal processing
matplotlib>=3.7.0        # Visualizations
praat-parselmouth>=0.4.3 # Formant extraction
soundfile>=0.12.0        # Audio I/O
rich>=13.0.0             # Terminal UI
click>=8.1.0             # CLI framework
```

---

## ğŸš€ Quick Start

### Option 1: Web GUI (Recommended - Most User-Friendly) ğŸ†•

```bash
python start_gui.py
```

Opens a beautiful web interface at `http://localhost:7860` with:
- ğŸ–±ï¸ **Drag-and-drop** file upload
- ğŸ“Š **Real-time** visualizations
- ğŸ“¥ **Download** JSON/Markdown reports
- ğŸ“ **Batch processing** with progress tracking
- ğŸ¨ **Modern UI** with dark theme

Perfect for: Visual analysis, presentations, non-technical users

### Option 2: Simple Command Line

```bash
# Analyze a single file
python analyze.py suspicious_call.wav

# Batch process a directory
python analyze.py --batch ./audio_samples/ -o ./results/

# Faster (no visualizations)
python analyze.py sample.wav --no-viz
```

Perfect for: Quick analysis, scripting, automation

### Option 3: Interactive TUI

```bash
python tui.py interactive
```

Terminal-based menu interface with full features.

Perfect for: Server environments, SSH sessions

### Option 4: Python API

```python
from pipeline import VoiceManipulationDetector

detector = VoiceManipulationDetector()
report = detector.analyze('sample.wav', output_dir='results/')

# Check results
if report['ALTERATION_DETECTED']:
    print(f"âš  MANIPULATION DETECTED")
    print(f"Confidence: {report['CONFIDENCE']}")
else:
    print(f"âœ“ No manipulation detected")
```

Perfect for: Integration, custom workflows, automation

---

## ğŸ“– Documentation

### Core Documentation

- **[USAGE.md](USAGE.md)** - Comprehensive usage guide with examples
- **[TECHNICAL.md](TECHNICAL.md)** - Technical implementation details
- **[API.md](API.md)** - Complete API reference
- **[DEPLOYMENT.md](DEPLOYMENT.md)** - Production deployment guide

### Understanding Reports

Each analysis generates a comprehensive report:

```json
{
  "ASSET_ID": "sample_001",
  "ALTERATION_DETECTED": true,
  "CONFIDENCE": "99% (Very High)",

  "PRESENTED_AS": "Female",          // Based on pitch (F0)
  "PROBABLE_SEX": "Male",            // Based on formants (physical)

  "DECEPTION_BASELINE_F0": "221.5 Hz (Median)",
  "PHYSICAL_BASELINE_FORMANTS": "F1: 498 Hz, F2: 1510 Hz, F3: 2490 Hz",

  "EVIDENCE_VECTOR_1_PITCH": "Pitch-Formant Incoherence Detected...",
  "EVIDENCE_VECTOR_2_TIME": "Phase Decoherence / Transient Smearing Detected...",
  "EVIDENCE_VECTOR_3_SPECTRAL": "Spectral Artifacts Detected...",

  "VERIFICATION": {
    "file_hash_sha256": "7bd4d4ce92be3174...",
    "report_hash_sha256": "6e5edefb6fd84dc9...",
    "timestamp_utc": "2025-10-29T23:05:08Z"
  }
}
```

### Confidence Levels

| Level | Description | Detection Methods Triggered |
|-------|-------------|----------------------------|
| **99% (Very High)** | Multiple independent confirmations | All 3 methods |
| **85% (High)** | Strong evidence | 2 methods |
| **60-75% (Medium)** | Moderate evidence | 1 method |
| **0% (Low)** | No manipulation detected | 0 methods |

---

## ğŸŒ Web GUI Features

### Launch the GUI

```bash
python start_gui.py

# Custom port
python start_gui.py --port=8080

# Create shareable public link
python start_gui.py --share
```

### GUI Interface

The web GUI provides **4 ways to interact** with the system:

#### 1. Single File Analysis Tab
- **Drag-and-drop** audio file upload
- **Real-time progress** updates (Phase 1-5)
- **Instant results** display with HTML formatting
- **Visual gallery** showing all 4 analysis plots
- **Download buttons** for JSON and Markdown reports

#### 2. Batch Processing Tab
- **Multi-file upload** support
- **Progress tracking** for each file
- **Summary statistics** table
- **CSV export** for batch results

#### 3. About & Help Tab
- **Detection methods** explanation
- **Confidence levels** guide
- **Interpretation** tips
- **Security** information

### GUI Screenshots

Access at: `http://localhost:7860`

**Features:**
- ğŸ¨ Dark theme interface
- ğŸ“± Responsive design
- âš¡ Real-time updates
- ğŸ”’ Secure (local processing)

---

## ğŸ’¡ Examples

### Example 1: Web GUI (Easiest)

```bash
python start_gui.py
```

Then:
1. Open browser to http://localhost:7860
2. Drag audio file onto upload area
3. Click "Analyze Audio"
4. View results and visualizations
5. Download reports

### Example 2: Basic CLI Analysis

```bash
python tui.py analyze suspicious_voice.wav
```

**Output:**
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
FORENSIC AUDIO ANALYSIS REPORT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ASSET_ID: suspicious_voice
ALTERATION DETECTED: True
CONFIDENCE: 99% (Very High)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
EVIDENCE VECTORS:
  [1] PITCH: Pitch-Formant Incoherence Detected
  [2] TIME: Phase Decoherence / Transient Smearing Detected
  [3] SPECTRAL: Spectral Artifacts Detected
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Example 2: Batch Processing

```python
from pipeline import VoiceManipulationDetector

detector = VoiceManipulationDetector()
reports = detector.batch_analyze(
    audio_dir='./evidence/',
    output_dir='./case_001_results/',
    pattern='*.wav'
)

# Generate summary
manipulated = sum(1 for r in reports if r['ALTERATION_DETECTED'])
print(f"Detected manipulation in {manipulated}/{len(reports)} files")
```

### Example 3: Verification

```python
from verification import OutputVerifier

verifier = OutputVerifier()
result = verifier.verify_report('results/sample_report.json')

if result['valid']:
    print(f"âœ“ Report verified - Timestamp: {result['timestamp']}")
else:
    print(f"âœ— Verification failed: {result['error']}")
```

### Example 4: Export to CSV

```python
from verification import ReportExporter

exporter = ReportExporter()
exporter.export_csv_summary(reports, 'case_summary.csv')
```

---

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
python test_pipeline.py
```

This will:
1. Generate 6 synthetic test samples (3 clean + 3 manipulated)
2. Analyze each sample through the full pipeline
3. Verify detection accuracy
4. Test cryptographic verification system
5. Generate complete reports and visualizations

**Expected Output:**
```
================================================================================
TEST RESULTS SUMMARY
================================================================================
Total Tests: 6
Passed: 4 (âœ“)
Failed: 2 (âš )
Success Rate: 66.7%

MANIPULATION DETECTION: 4/4 PASSED (100%)
  âœ“ Male voice pitch-shifted       â†’ DETECTED (99% confidence)
  âœ“ Female voice pitch-shifted     â†’ DETECTED (85% confidence)
  âœ“ Pitch + time manipulation      â†’ DETECTED (99% confidence)
  âœ“ Time-stretch only              â†’ DETECTED (99% confidence)
```

---

## ğŸ“ Project Structure

```
voice/
â”‚
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ USAGE.md                     # Comprehensive usage guide
â”œâ”€â”€ TECHNICAL.md                 # Technical documentation
â”œâ”€â”€ API.md                       # API reference
â”œâ”€â”€ DEPLOYMENT.md                # Deployment guide
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ phase1_baseline.py           # PHASE 1: F0 Analysis
â”œâ”€â”€ phase2_formants.py           # PHASE 2: Formant Analysis
â”œâ”€â”€ phase3_artifacts.py          # PHASE 3: Manipulation Detection
â”œâ”€â”€ phase5_ai_detection.py       # PHASE 4: AI Voice Detection
â”œâ”€â”€ phase4_report.py             # PHASE 5: Report Synthesis
â”‚
â”œâ”€â”€ pipeline.py                  # Main orchestrator
â”‚
â”œâ”€â”€ start_gui.py                 # ğŸ†• Web GUI Launcher
â”œâ”€â”€ gui_app.py                   # ğŸ†• Gradio Web Interface
â”œâ”€â”€ gui_utils.py                 # ğŸ†• GUI Helper Functions
â”œâ”€â”€ tui.py                       # Terminal User Interface
â”œâ”€â”€ analyze.py                   # Simple CLI Interface
â”‚
â”œâ”€â”€ visualizer.py                # Visualization generator
â”œâ”€â”€ verification.py              # Cryptographic verification
â”‚
â”œâ”€â”€ download_samples.py          # Sample generator
â”œâ”€â”€ example.py                   # Usage examples
â””â”€â”€ test_pipeline.py             # Test suite
```

---

## ğŸ”§ Technical Details

### Detection Methods

1. **Pitch-Formant Incoherence**
   - Compares F0 (fundamental frequency) vs formants (F1, F2, F3)
   - Detects physical impossibilities in voice characteristics
   - Primary method for pitch-shift detection

2. **Mel Spectrogram Analysis**
   - Identifies unnatural harmonic structures
   - Detects consistent computational noise floor
   - Finds spectral discontinuities

3. **Phase Coherence Analysis**
   - Analyzes STFT phase information
   - Detects transient smearing from time-stretching
   - Identifies phase discontinuities

### Algorithms Used

- **F0 Extraction:** `librosa.piptrack` with adaptive thresholding
- **Formant Analysis:** Praat Burg algorithm via `parselmouth`
- **Phase Analysis:** STFT with phase unwrapping
- **Artifact Detection:** Statistical analysis of spectral features

### Supported Formats

- WAV, MP3, FLAC, OGG, M4A (via librosa)
- Sample rates: Any (automatically resampled)
- Duration: Up to 10 minutes recommended

---

## ğŸ›¡ï¸ Security & Privacy

### Security Features

- âœ… **Sandboxed execution** (no network access required)
- âœ… **Read-only file operations** (no modification of source audio)
- âœ… **Cryptographic verification** (SHA-256 checksums)
- âœ… **Tamper-evident reports** (signed outputs)
- âœ… **Resource limiting** (DoS protection)

### Privacy Considerations

- No audio data is sent to external servers
- All processing is local and offline
- No personally identifiable information is stored
- Original audio files are never modified

### Chain of Custody

Each report includes:
- Timestamp (UTC)
- Audio file hash
- Analysis pipeline version
- Cryptographic signature

---

## ğŸ¤ Use Cases

### Authorized Applications

- âœ… **Forensic investigations** (law enforcement, legal proceedings)
- âœ… **Security testing** (authorized penetration testing)
- âœ… **Academic research** (voice processing studies)
- âœ… **Quality assurance** (detecting processing artifacts)
- âœ… **CTF challenges** (cybersecurity competitions)

### Prohibited Applications

- âŒ Unauthorized surveillance
- âŒ Privacy violations
- âŒ Harassment or stalking
- âŒ Discrimination based on voice characteristics

---

## ğŸ“Š Performance

### Benchmarks

| Audio Duration | Analysis Time | Memory Usage |
|---------------|---------------|--------------|
| 3 seconds     | ~3-5 seconds  | ~200 MB      |
| 30 seconds    | ~8-12 seconds | ~400 MB      |
| 3 minutes     | ~25-35 seconds| ~800 MB      |

*Tested on: Intel i7-9750H, 16GB RAM*

### Optimization Tips

- Disable visualizations with `--no-viz` for faster processing
- Use batch mode for multiple files (shared initialization)
- Limit audio duration for large files: `librosa.load(..., duration=30.0)`

---

## ğŸ› Troubleshooting

### Common Issues

**Issue:** "No module named 'librosa'"
**Solution:** Run `pip install -r requirements.txt`

**Issue:** Parselmouth errors on certain files
**Solution:** Ensure audio is valid format (WAV, MP3). Try converting with `ffmpeg`

**Issue:** False positives on synthetic/generated audio
**Expected:** Synthetic audio has unnatural characteristics that may trigger detection

**Issue:** Memory errors on large files
**Solution:** Limit duration: `y, sr = librosa.load('file.wav', duration=60.0)`

### Debug Mode

Enable verbose logging:

```python
import logging
logging.basicConfig(level=logging.DEBUG)

detector = VoiceManipulationDetector()
report = detector.analyze('sample.wav')
```

---

## ğŸ—ºï¸ Roadmap

### Current Version: 1.0.0

- [x] Multi-phase detection pipeline
- [x] Interactive TUI
- [x] Cryptographic verification
- [x] Comprehensive visualizations
- [x] Batch processing
- [x] Test suite

### Planned Features

- [ ] Real-time stream analysis
- [ ] Machine learning enhancement (optional deepfake detection)
- [ ] REST API server mode
- [ ] Docker containerization
- [ ] GPU acceleration
- [ ] Additional language support

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

This implementation is based on the **Tactical Implementation Specification (TIS)** for forensic voice analysis.

### Technologies Used

- [Librosa](https://librosa.org/) - Audio analysis
- [Praat-Parselmouth](https://parselmouth.readthedocs.io/) - Formant extraction
- [Rich](https://rich.readthedocs.io/) - Terminal UI
- [NumPy](https://numpy.org/) & [SciPy](https://scipy.org/) - Scientific computing

---

## ğŸ“ Support

For issues, questions, or contributions:

1. Check the [documentation](USAGE.md)
2. Review [examples](example.py)
3. Run the [test suite](test_pipeline.py)
4. Consult [technical documentation](TECHNICAL.md)

---

## âš–ï¸ Ethical Use Statement

This tool is designed for **authorized security testing, forensic analysis, and research purposes only**. Users must:

- Obtain proper authorization before analyzing voice recordings
- Comply with applicable laws and regulations
- Respect privacy and consent requirements
- Use results responsibly and ethically

**Unauthorized use for surveillance, discrimination, or privacy violation is strictly prohibited.**

---

<div align="center">

**Built with ğŸ”¬ for forensic audio analysis**

</div>
